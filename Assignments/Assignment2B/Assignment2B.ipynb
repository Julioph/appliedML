{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from SVClassifier import SVClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "class LinearClassifier(BaseEstimator):\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        return X.dot(self.w)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        scores = self.decision_function(X)\n",
    "        print(scores)\n",
    "        out = np.select([scores >= 0.0 , scores < 0.0], [self.positive_class, self.negative_class])\n",
    "        return out\n",
    "    \n",
    "    def find_classes(self, Y):\n",
    "        classes = sorted(set(Y))\n",
    "        if len(classes) != 2:\n",
    "            raise Exception(\"This is not a binary classification problem\")\n",
    "        \n",
    "        self.negative_class = classes[0]\n",
    "        self.positive_class = classes[1]\n",
    "         \n",
    "    \n",
    "    def encode_output(self, Y):\n",
    "        encoded = np.array([1 if y==self.positive_class else -1 for y in Y])\n",
    "\n",
    "        return encoded\n",
    "\n",
    "class SVClassifier(LinearClassifier):\n",
    "    \n",
    "    def __init__(self, n_iter=50):\n",
    "        self.n_iter = n_iter\n",
    "        \n",
    "    def fit(self, X, Y, regularization_param):\n",
    "        \"\"\"\n",
    "        Train a linear classifier using the SVC learning algorithm.\n",
    "        \"\"\"\n",
    "        self.find_classes(Y)\n",
    "\n",
    "        Ye = self.encode_output(Y)\n",
    "\n",
    "        # If necessary, convert the sparse matrix returned by a vectorizer\n",
    "        # into a normal NumPy matrix.\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            X = X.toarray()\n",
    "\n",
    "        # Initialize the weight vector to all zeros.\n",
    "        n_features = X.shape[1]\n",
    "        self.w = np.zeros(n_features)\n",
    "\n",
    "        # start iterations\n",
    "        t = 0\n",
    "        for i in range(self.n_iter):\n",
    "\n",
    "            for x_i, y_i in zip(X, Ye):\n",
    "                t += 1\n",
    "\n",
    "                # Calculate steplength\n",
    "                eta = 1 / (regularization_param * t)\n",
    "                # Calculate score\n",
    "                score = x_i.dot(self.w)\n",
    "\n",
    "                if y_i * score < 1.0:\n",
    "                    self.w = ((1 - eta * regularization_param) * self.w) + ((eta * y_i) * x_i)\n",
    "                else:\n",
    "                    self.w = (1 - eta * regularization_param) * self.w    \n",
    "\n",
    "\n",
    "class LogisticRegressionClassifier(LinearClassifier):\n",
    "    def __init__(self, n_iter=50):\n",
    "        self.n_iter = n_iter\n",
    "        \n",
    "    def fit(self, X, Y, regularization_param):\n",
    "        self.find_classes(Y)\n",
    "        \n",
    "        Y_encoded = self.encode_output(Y)\n",
    "        \n",
    "        # If necessary, convert the sparse matrix returned by a vectorizer\n",
    "        # into a normal NumPy matrix.\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            X = X.toarray()\n",
    "            \n",
    "        n_features = X.shape[1]\n",
    "        self.w = np.zeros(n_features)\n",
    "        \n",
    "        #Begin iterations\n",
    "        t = 0\n",
    "        for i in range(self.n_iter):\n",
    "            for x_i, y_i in zip(X,Y_encoded):\n",
    "                t += 1\n",
    "                eta = 1 / (t * regularization_param)\n",
    "                z = x_i.dot(self.w)\n",
    "                self.w = ((1 - eta * regularization_param) * self.w) + eta * (y_i / (1 + np.exp(y_i * z)) * x_i) \n",
    "                    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[-0.80513534  0.26354307  0.78785032 ... -0.73691132 -0.00379889\n",
      " -1.73332649]\n",
      "Training duration: 10.8021 seconds.\n",
      "Prediction duration: 0.7879 seconds.\n",
      "Program duration: 11.6728 seconds.\n",
      "\n",
      "Accuracy: 0.8363.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def read_data(corpus_file):\n",
    "    X = []\n",
    "    Y = []\n",
    "    with open(corpus_file, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            _, y, _, x = line.split(maxsplit=3)\n",
    "            X.append(x.strip())\n",
    "            Y.append(y)\n",
    "    return X, Y\n",
    "\n",
    "t4 = time.time()\n",
    "# Read all the documents.\n",
    "X, Y = read_data('pa2b/data/all_sentiment_shuffled.txt')\n",
    "\n",
    "# Split into training and test parts.\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Set up the preprocessing steps and the classifier.\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(),\n",
    "    SelectKBest(k=1000),\n",
    "    Normalizer(),\n",
    "    LogisticRegressionClassifier(n_iter=50)\n",
    ")\n",
    "\n",
    "#Train the classifier (adjust weights) and time it\n",
    "t0 = time.time()\n",
    "pipeline.fit(Xtrain, Ytrain, logisticregressionclassifier__regularization_param=1/len(Xtrain))\n",
    "t1 = time.time()\n",
    "\n",
    "#Evaluate on the test set\n",
    "t2 = time.time()\n",
    "Yguess = pipeline.predict(Xtest)\n",
    "t3 = time.time()\n",
    "t5 = time.time()\n",
    "\n",
    "print('Training duration: {:.4f} seconds.'.format(t1 - t0))\n",
    "print('Prediction duration: {:.4f} seconds.'.format(t3 - t2))\n",
    "print('Program duration: {:.4f} seconds.\\n'.format(t5 - t4))\n",
    "print('Accuracy: {:.4f}.'.format(accuracy_score(Ytest, Yguess)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "[(3, 7), (1, 9), (2, 8)]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 81
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = [9,8,7]\n",
    "taps = list(zip(a,b))\n",
    "random.shuffle(taps)\n",
    "taps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-46474081",
   "language": "python",
   "display_name": "PyCharm (Assignment4)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}